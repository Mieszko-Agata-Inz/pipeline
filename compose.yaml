services:
  query_api:
    image: query_api
    build: 
      context: ./query_api
      dockerfile: Dockerfile
    ports:
      - "80:80"
    env_file:
      - ./query_api/.env
    depends_on:
      - "kafka"
  zookeeper:
    image: confluentinc/cp-zookeeper:6.0.14
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: "2181"
  kafka:
    image: confluentinc/cp-kafka:6.0.14
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 0
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_ADVERTISED_LISTENERS: "INTERNAL://kafka:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092"
      KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
    depends_on:
      - "zookeeper"
  redis:
    image: redis:6.2-alpine
    restart: always
    ports:
      - '6379:6379'
    command: redis-server --save "" --appendonly no --loglevel warning --requirepass eYVX7EwVmmxKPCDmwMtyKVge8oLd2t81
  spark:
    image: docker.io/bitnami/spark:3.3
    container_name: spark_master
    hostname: spark_master
    user: root
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - '8080:8080'
    depends_on:
      - "redis"
      - "kafka"
  python_scripts:
    image: scripts
    build:
      context: ./spark_processing
      dockerfile: Dockerfile
    depends_on:
      - "spark"
      - "query_api"