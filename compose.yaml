services:
  query_api:
    image: query_api
    build: 
      context: ./query_api
      dockerfile: Dockerfile
    ports:
      - "80:80"
    env_file:
      - ./query_api/.env
    depends_on:
      - "kafka"
  zookeeper:
    image: confluentinc/cp-zookeeper:6.0.14
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: "2181"
  kafka:
    image: confluentinc/cp-kafka:6.0.14
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 0
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_ADVERTISED_LISTENERS: "INTERNAL://kafka:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,PLAINTEXT_HOST://kafka:29092"
      KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
    command: sh -c "((sleep 15 && kafka-topics --create --zookeeper zookeeper:2181 --replication-factor 1 --partitions 1 --topic weather_data)&) && /etc/confluent/docker/run "
    depends_on:
      - "zookeeper"
  redis:
    image: redis:6.2-alpine
    restart: always
    ports:
      - '6379:6379'
    command: redis-server --save "" --appendonly no --loglevel warning --requirepass eYVX7EwVmmxKPCDmwMtyKVge8oLd2t81
  data_processing:
    image: 'data_processing'
    build: 
      context: ./data_processing
      dockerfile: Dockerfile
    ports:
      - "81:81"
    depends_on:
      - "kafka"
      - "redis"
      - "query_api"